{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import _pickle as pickle\n",
    "import dtale\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.read_csv(r'C:\\Users\\Alex Willett\\Desktop\\research_tome\\stockpup_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Shares</th>\n",
       "      <th>Shares split adjusted</th>\n",
       "      <th>Split factor</th>\n",
       "      <th>Assets</th>\n",
       "      <th>Current Assets</th>\n",
       "      <th>Liabilities</th>\n",
       "      <th>Current Liabilities</th>\n",
       "      <th>Shareholders equity</th>\n",
       "      <th>Non-controlling interest</th>\n",
       "      <th>...</th>\n",
       "      <th>P/B ratio</th>\n",
       "      <th>P/E ratio</th>\n",
       "      <th>Cumulative dividends per share</th>\n",
       "      <th>Dividend payout ratio</th>\n",
       "      <th>Long-term debt to equity ratio</th>\n",
       "      <th>Equity to assets ratio</th>\n",
       "      <th>Net margin</th>\n",
       "      <th>Asset turnover</th>\n",
       "      <th>Free cash flow per share</th>\n",
       "      <th>Current ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.060170</td>\n",
       "      <td>0.060170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.011116</td>\n",
       "      <td>1.505420</td>\n",
       "      <td>2.212896</td>\n",
       "      <td>5.757136</td>\n",
       "      <td>3.477486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-137.179487</td>\n",
       "      <td>-4.020246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.164196</td>\n",
       "      <td>0.164196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.911624</td>\n",
       "      <td>5.675302</td>\n",
       "      <td>9.182531</td>\n",
       "      <td>14.821592</td>\n",
       "      <td>5.601034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-40.465919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.230090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>17.241379</td>\n",
       "      <td>-7.966629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.739888</td>\n",
       "      <td>0.739888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.640220</td>\n",
       "      <td>5.819611</td>\n",
       "      <td>8.034188</td>\n",
       "      <td>9.880478</td>\n",
       "      <td>7.405141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.739130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.223535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-144.117647</td>\n",
       "      <td>-3.696398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.088384</td>\n",
       "      <td>0.088384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.293769</td>\n",
       "      <td>-3.430592</td>\n",
       "      <td>16.044304</td>\n",
       "      <td>11.312545</td>\n",
       "      <td>5.242165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.335456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.696591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-553.333333</td>\n",
       "      <td>-13.246196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.066338</td>\n",
       "      <td>0.066338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.390096</td>\n",
       "      <td>-8.478301</td>\n",
       "      <td>-5.535860</td>\n",
       "      <td>0.912052</td>\n",
       "      <td>1.353546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.260870</td>\n",
       "      <td>-25.917859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.775008</td>\n",
       "      <td>-8.163265</td>\n",
       "      <td>-6.47482</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-9.304025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    Shares  Shares split adjusted  Split factor    Assets  \\\n",
       "0           0  0.060170               0.060170           0.0  3.011116   \n",
       "1           1  0.164196               0.164196           0.0  6.911624   \n",
       "2           2  0.739888               0.739888           0.0  7.640220   \n",
       "3           3  0.088384               0.088384           0.0  9.293769   \n",
       "4           4  0.066338               0.066338           0.0 -1.390096   \n",
       "\n",
       "   Current Assets  Liabilities  Current Liabilities  Shareholders equity  \\\n",
       "0        1.505420     2.212896             5.757136             3.477486   \n",
       "1        5.675302     9.182531            14.821592             5.601034   \n",
       "2        5.819611     8.034188             9.880478             7.405141   \n",
       "3       -3.430592    16.044304            11.312545             5.242165   \n",
       "4       -8.478301    -5.535860             0.912052             1.353546   \n",
       "\n",
       "   Non-controlling interest  ...  P/B ratio  P/E ratio  \\\n",
       "0                       0.0  ...   0.000000   0.000000   \n",
       "1                       0.0  ... -40.465919   0.000000   \n",
       "2                       0.0  ... -31.739130   0.000000   \n",
       "3                       0.0  ...  -2.335456   0.000000   \n",
       "4                       0.0  ... -28.260870 -25.917859   \n",
       "\n",
       "   Cumulative dividends per share  Dividend payout ratio  \\\n",
       "0                             0.0                    0.0   \n",
       "1                             0.0                    0.0   \n",
       "2                             0.0                    0.0   \n",
       "3                             0.0                    0.0   \n",
       "4                             0.0                    0.0   \n",
       "\n",
       "   Long-term debt to equity ratio  Equity to assets ratio  Net margin  \\\n",
       "0                             0.0                0.459442    0.000000   \n",
       "1                             0.0               -1.230090    0.000000   \n",
       "2                             0.0               -0.223535    0.000000   \n",
       "3                             0.0               -3.696591    0.000000   \n",
       "4                             0.0                2.775008   -8.163265   \n",
       "\n",
       "   Asset turnover  Free cash flow per share  Current ratio  \n",
       "0         0.00000               -137.179487      -4.020246  \n",
       "1         0.00000                 17.241379      -7.966629  \n",
       "2         0.00000               -144.117647      -3.696398  \n",
       "3         0.00000               -553.333333     -13.246196  \n",
       "4        -6.47482               -100.000000      -9.304025  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 features to choose from\n"
     ]
    }
   ],
   "source": [
    "X = stocks.drop(['Price', 'Price high', 'Price low','Unnamed: 0'], 1)\n",
    "y = stocks.Price\n",
    "\n",
    "# Maximum numbers of features we need to select\n",
    "num_feats = 15\n",
    "feature_name = list(X.columns)\n",
    "\n",
    "# how many features to choose from before selections\n",
    "print(str(len(feature_name)), 'features to choose from')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://LAPTOP-DL3DBF8J:40001/dtale/main/2\n",
      "It looks like this data may have already been loaded to D-Tale based on shape and column names. Here is URL of the data that seems to match it:\n",
      "\n",
      "None\n",
      "\n",
      "If you still want to load this data please use the following command:\n",
      "\n",
      "dtale.show(df, ignore_duplicate=True)\n"
     ]
    }
   ],
   "source": [
    "d_X = dtale.show(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 selected features\n"
     ]
    }
   ],
   "source": [
    "def cor_selector(X, y,num_feats):\n",
    "    cor_list = []\n",
    "    feature_name = X.columns.tolist()\n",
    "    # calculate the correlation with y for each feature\n",
    "    for i in X.columns.tolist():\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "    # replace NaN with 0\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    # feature name\n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
    "    # feature selection? 0 for not select, 1 for select\n",
    "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "    return cor_support, cor_feature\n",
    "cor_support, cor_feature = cor_selector(X, y,num_feats)\n",
    "print(str(len(cor_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Long-term debt to equity ratio',\n",
       " 'Asset turnover',\n",
       " 'Shares split adjusted',\n",
       " 'Equity to assets ratio',\n",
       " 'Dividend payout ratio',\n",
       " 'Long-term debt',\n",
       " 'Split factor',\n",
       " 'ROA',\n",
       " 'ROE',\n",
       " 'Shares',\n",
       " 'Liabilities',\n",
       " 'Assets',\n",
       " 'Shareholders equity',\n",
       " 'Book value of equity per share',\n",
       " 'P/B ratio']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-08 15:37:26,107 - WARNING  - From C:\\Users\\Alex Willett\\Anacondaweed\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "2020-04-08 15:37:26,369 - WARNING  - From C:\\Users\\Alex Willett\\Anacondaweed\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(X.shape[1],))\n",
    "dense_layer_1 = Dense(100, activation='relu')(input_layer)\n",
    "dense_layer_2 = Dense(50, activation='relu')(dense_layer_1)\n",
    "dense_layer_3 = Dense(25, activation='relu')(dense_layer_2)\n",
    "output = Dense(1)(dense_layer_3)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(X.shape[1],))\n",
    "dense_layer_1 = Dense(100, activation='relu')(input_layer)\n",
    "dense_layer_2 = Dense(50, activation='relu')(dense_layer_1)\n",
    "dense_layer_3 = Dense(25, activation='relu')(dense_layer_2)\n",
    "output = Dense(1)(dense_layer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-08 15:37:52,164 - WARNING  - From C:\\Users\\Alex Willett\\Anacondaweed\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35561 samples, validate on 8891 samples\n",
      "Epoch 1/100\n",
      "35561/35561 [==============================] - 25s 715us/sample - loss: 6912.9371 - mean_squared_error: 6912.8408 - val_loss: 3450.4548 - val_mean_squared_error: 3450.4565\n",
      "Epoch 2/100\n",
      "35561/35561 [==============================] - 24s 671us/sample - loss: 6922.9767 - mean_squared_error: 6922.9565 - val_loss: 3059.1693 - val_mean_squared_error: 3059.1694\n",
      "Epoch 3/100\n",
      "35561/35561 [==============================] - 24s 679us/sample - loss: 6372.9256 - mean_squared_error: 6372.8936 - val_loss: 2506.9780 - val_mean_squared_error: 2506.9761\n",
      "Epoch 4/100\n",
      "35561/35561 [==============================] - 25s 693us/sample - loss: 6113.8769 - mean_squared_error: 6113.7959 - val_loss: 2900.4452 - val_mean_squared_error: 2900.4414\n",
      "Epoch 5/100\n",
      "35561/35561 [==============================] - 28s 777us/sample - loss: 6608.7504 - mean_squared_error: 6608.7119 - val_loss: 2864.1900 - val_mean_squared_error: 2864.1951\n",
      "Epoch 6/100\n",
      "35561/35561 [==============================] - 25s 711us/sample - loss: 6376.4248 - mean_squared_error: 6376.3740 - val_loss: 3112.3776 - val_mean_squared_error: 3112.3762\n",
      "Epoch 7/100\n",
      "35561/35561 [==============================] - 24s 666us/sample - loss: 6581.9077 - mean_squared_error: 6581.7891 - val_loss: 3316.8142 - val_mean_squared_error: 3316.8130\n",
      "Epoch 8/100\n",
      "35561/35561 [==============================] - 27s 747us/sample - loss: 6955.6515 - mean_squared_error: 6955.6226 - val_loss: 2733.1370 - val_mean_squared_error: 2733.1379\n",
      "Epoch 9/100\n",
      "35561/35561 [==============================] - 27s 751us/sample - loss: 5474.9086 - mean_squared_error: 5474.8384 - val_loss: 3279.2930 - val_mean_squared_error: 3279.2974\n",
      "Epoch 10/100\n",
      "35561/35561 [==============================] - 29s 813us/sample - loss: 6468.4935 - mean_squared_error: 6468.3882 - val_loss: 3390.2115 - val_mean_squared_error: 3390.2122\n",
      "Epoch 11/100\n",
      "35561/35561 [==============================] - 26s 742us/sample - loss: 6588.9544 - mean_squared_error: 6588.8721 - val_loss: 2939.0961 - val_mean_squared_error: 2939.0952\n",
      "Epoch 12/100\n",
      "35561/35561 [==============================] - 25s 714us/sample - loss: 6173.6405 - mean_squared_error: 6173.6084 - val_loss: 2935.5752 - val_mean_squared_error: 2935.5769\n",
      "Epoch 13/100\n",
      "35561/35561 [==============================] - 26s 727us/sample - loss: 5515.4097 - mean_squared_error: 5515.3496 - val_loss: 2790.2327 - val_mean_squared_error: 2790.2336\n",
      "Epoch 14/100\n",
      "35561/35561 [==============================] - 26s 741us/sample - loss: 6347.0161 - mean_squared_error: 6346.9771 - val_loss: 2838.9682 - val_mean_squared_error: 2838.9688\n",
      "Epoch 15/100\n",
      "35561/35561 [==============================] - 26s 740us/sample - loss: 5699.6876 - mean_squared_error: 5699.6470 - val_loss: 2827.7390 - val_mean_squared_error: 2827.7351\n",
      "Epoch 16/100\n",
      "35561/35561 [==============================] - 26s 726us/sample - loss: 5195.6595 - mean_squared_error: 5195.5835 - val_loss: 3555.9967 - val_mean_squared_error: 3555.9961\n",
      "Epoch 17/100\n",
      "35561/35561 [==============================] - 29s 826us/sample - loss: 5688.0603 - mean_squared_error: 5688.0562 - val_loss: 2191.8296 - val_mean_squared_error: 2191.8289\n",
      "Epoch 18/100\n",
      "35561/35561 [==============================] - 24s 676us/sample - loss: 6314.9354 - mean_squared_error: 6314.9380 - val_loss: 3279.8494 - val_mean_squared_error: 3279.8486\n",
      "Epoch 19/100\n",
      "35561/35561 [==============================] - 26s 728us/sample - loss: 6302.4523 - mean_squared_error: 6302.3979 - val_loss: 3327.3851 - val_mean_squared_error: 3327.3860\n",
      "Epoch 20/100\n",
      "35561/35561 [==============================] - 28s 782us/sample - loss: 5802.3449 - mean_squared_error: 5802.2739 - val_loss: 3463.4510 - val_mean_squared_error: 3463.4495\n",
      "Epoch 21/100\n",
      "35561/35561 [==============================] - 27s 750us/sample - loss: 6282.3227 - mean_squared_error: 6282.3032 - val_loss: 2788.2934 - val_mean_squared_error: 2788.2915\n",
      "Epoch 22/100\n",
      "35561/35561 [==============================] - 27s 757us/sample - loss: 5233.2906 - mean_squared_error: 5233.2139 - val_loss: 2997.7799 - val_mean_squared_error: 2997.7778\n",
      "Epoch 23/100\n",
      "35561/35561 [==============================] - 25s 713us/sample - loss: 6100.3737 - mean_squared_error: 6100.2690 - val_loss: 3243.3894 - val_mean_squared_error: 3243.3833\n",
      "Epoch 24/100\n",
      "35561/35561 [==============================] - 25s 700us/sample - loss: 6484.7887 - mean_squared_error: 6484.7681 - val_loss: 2981.3307 - val_mean_squared_error: 2981.3318\n",
      "Epoch 25/100\n",
      "35561/35561 [==============================] - 25s 700us/sample - loss: 6018.3554 - mean_squared_error: 6018.3379 - val_loss: 3052.3671 - val_mean_squared_error: 3052.3665\n",
      "Epoch 26/100\n",
      "35561/35561 [==============================] - 25s 714us/sample - loss: 5899.1690 - mean_squared_error: 5899.1040 - val_loss: 2761.0266 - val_mean_squared_error: 2761.0256\n",
      "Epoch 27/100\n",
      "35561/35561 [==============================] - 25s 701us/sample - loss: 5826.6604 - mean_squared_error: 5826.6372 - val_loss: 3135.0087 - val_mean_squared_error: 3135.0083\n",
      "Epoch 28/100\n",
      "35561/35561 [==============================] - 24s 683us/sample - loss: 5565.4715 - mean_squared_error: 5565.4106 - val_loss: 2521.3465 - val_mean_squared_error: 2521.3452\n",
      "Epoch 29/100\n",
      "35561/35561 [==============================] - 29s 820us/sample - loss: 5573.5599 - mean_squared_error: 5573.5483 - val_loss: 3178.5747 - val_mean_squared_error: 3178.5735\n",
      "Epoch 30/100\n",
      "35561/35561 [==============================] - 27s 769us/sample - loss: 5947.4783 - mean_squared_error: 5947.4048 - val_loss: 2503.7967 - val_mean_squared_error: 2503.8013\n",
      "Epoch 31/100\n",
      "35561/35561 [==============================] - 25s 702us/sample - loss: 5721.7291 - mean_squared_error: 5721.6792 - val_loss: 3442.7678 - val_mean_squared_error: 3442.7703\n",
      "Epoch 32/100\n",
      "35561/35561 [==============================] - 23s 643us/sample - loss: 5533.5876 - mean_squared_error: 5533.5498 - val_loss: 2684.3987 - val_mean_squared_error: 2684.3975\n",
      "Epoch 33/100\n",
      "35561/35561 [==============================] - 27s 758us/sample - loss: 5691.6030 - mean_squared_error: 5691.5874 - val_loss: 3459.4308 - val_mean_squared_error: 3459.4304\n",
      "Epoch 34/100\n",
      "35561/35561 [==============================] - 27s 751us/sample - loss: 6135.0215 - mean_squared_error: 6134.9644 - val_loss: 3897.8328 - val_mean_squared_error: 3897.8328\n",
      "Epoch 35/100\n",
      "35561/35561 [==============================] - 27s 769us/sample - loss: 6221.4432 - mean_squared_error: 6221.4067 - val_loss: 3548.8102 - val_mean_squared_error: 3548.8123\n",
      "Epoch 36/100\n",
      "35561/35561 [==============================] - 23s 656us/sample - loss: 4708.4658 - mean_squared_error: 4708.4556 - val_loss: 4854.8404 - val_mean_squared_error: 4854.8398\n",
      "Epoch 37/100\n",
      "35561/35561 [==============================] - 23s 647us/sample - loss: 4508.9669 - mean_squared_error: 4508.9043 - val_loss: 3209.7086 - val_mean_squared_error: 3209.7043\n",
      "Epoch 38/100\n",
      "35561/35561 [==============================] - 24s 678us/sample - loss: 6126.7506 - mean_squared_error: 6126.6948 - val_loss: 5965.4236 - val_mean_squared_error: 5965.4302\n",
      "Epoch 39/100\n",
      "35561/35561 [==============================] - 22s 632us/sample - loss: 6067.6635 - mean_squared_error: 6067.5908 - val_loss: 3554.9199 - val_mean_squared_error: 3554.9189\n",
      "Epoch 40/100\n",
      "35561/35561 [==============================] - 22s 626us/sample - loss: 6515.5027 - mean_squared_error: 6515.3643 - val_loss: 4619.7637 - val_mean_squared_error: 4619.7549\n",
      "Epoch 41/100\n",
      "35561/35561 [==============================] - 23s 643us/sample - loss: 5793.3655 - mean_squared_error: 5793.3364 - val_loss: 5578.9384 - val_mean_squared_error: 5578.9258\n",
      "Epoch 42/100\n",
      "35561/35561 [==============================] - 23s 644us/sample - loss: 5451.6668 - mean_squared_error: 5451.5669 - val_loss: 2838.3750 - val_mean_squared_error: 2838.3728\n",
      "Epoch 43/100\n",
      "35561/35561 [==============================] - 23s 656us/sample - loss: 6292.2068 - mean_squared_error: 6292.1938 - val_loss: 3648.6864 - val_mean_squared_error: 3648.6863\n",
      "Epoch 44/100\n",
      "35561/35561 [==============================] - 23s 633us/sample - loss: 5639.3715 - mean_squared_error: 5639.3428 - val_loss: 2441.2048 - val_mean_squared_error: 2441.1975\n",
      "Epoch 45/100\n",
      "35561/35561 [==============================] - 22s 623us/sample - loss: 7885.5981 - mean_squared_error: 7885.4458 - val_loss: 3476.8549 - val_mean_squared_error: 3476.8540\n",
      "Epoch 46/100\n",
      "35561/35561 [==============================] - 23s 640us/sample - loss: 3639.9038 - mean_squared_error: 3639.8933 - val_loss: 4306.6610 - val_mean_squared_error: 4306.6543\n",
      "Epoch 47/100\n",
      "35561/35561 [==============================] - 22s 625us/sample - loss: 4195.4952 - mean_squared_error: 4195.4766 - val_loss: 2894.5695 - val_mean_squared_error: 2894.5657\n",
      "Epoch 48/100\n",
      "35561/35561 [==============================] - 22s 630us/sample - loss: 5259.1093 - mean_squared_error: 5259.0249 - val_loss: 3617.4231 - val_mean_squared_error: 3617.4207\n",
      "Epoch 49/100\n",
      "35561/35561 [==============================] - 23s 636us/sample - loss: 6657.3860 - mean_squared_error: 6657.3813 - val_loss: 5503.4168 - val_mean_squared_error: 5503.4004\n",
      "Epoch 50/100\n",
      "35561/35561 [==============================] - 22s 629us/sample - loss: 6377.5783 - mean_squared_error: 6377.5112 - val_loss: 3099.3575 - val_mean_squared_error: 3099.3555\n",
      "Epoch 51/100\n",
      "35561/35561 [==============================] - 23s 634us/sample - loss: 5957.3377 - mean_squared_error: 5957.3091 - val_loss: 3794.8681 - val_mean_squared_error: 3794.8713\n",
      "Epoch 52/100\n",
      "35561/35561 [==============================] - 22s 620us/sample - loss: 5467.3740 - mean_squared_error: 5467.3599 - val_loss: 5925.1431 - val_mean_squared_error: 5925.1416\n",
      "Epoch 53/100\n",
      "35561/35561 [==============================] - 22s 621us/sample - loss: 5123.5620 - mean_squared_error: 5123.5376 - val_loss: 2323.1837 - val_mean_squared_error: 2323.1833\n",
      "Epoch 54/100\n",
      "35561/35561 [==============================] - 24s 668us/sample - loss: 3268.1005 - mean_squared_error: 3268.0803 - val_loss: 3423.2162 - val_mean_squared_error: 3423.2178\n",
      "Epoch 55/100\n",
      "35561/35561 [==============================] - 22s 624us/sample - loss: 6073.1064 - mean_squared_error: 6073.0522 - val_loss: 7204.5460 - val_mean_squared_error: 7204.5483\n",
      "Epoch 56/100\n",
      "35561/35561 [==============================] - 24s 667us/sample - loss: 6187.9971 - mean_squared_error: 6187.9282 - val_loss: 2950.0830 - val_mean_squared_error: 2950.0771\n",
      "Epoch 57/100\n",
      "35561/35561 [==============================] - 23s 641us/sample - loss: 6032.4113 - mean_squared_error: 6032.3970 - val_loss: 4800.5668 - val_mean_squared_error: 4800.5630\n",
      "Epoch 58/100\n",
      "35561/35561 [==============================] - 22s 629us/sample - loss: 7137.2821 - mean_squared_error: 7137.1831 - val_loss: 4822.2211 - val_mean_squared_error: 4822.2241\n",
      "Epoch 59/100\n",
      "35561/35561 [==============================] - 22s 631us/sample - loss: 6082.8661 - mean_squared_error: 6082.7690 - val_loss: 5152.0370 - val_mean_squared_error: 5152.0337\n",
      "Epoch 60/100\n",
      "35561/35561 [==============================] - 22s 622us/sample - loss: 6518.1842 - mean_squared_error: 6518.1382 - val_loss: 2131.4493 - val_mean_squared_error: 2131.4492\n",
      "Epoch 61/100\n",
      "35561/35561 [==============================] - 23s 640us/sample - loss: 4372.1521 - mean_squared_error: 4372.1104 - val_loss: 2637.3908 - val_mean_squared_error: 2637.3921\n",
      "Epoch 62/100\n",
      "35561/35561 [==============================] - 22s 631us/sample - loss: 5813.3844 - mean_squared_error: 5813.3535 - val_loss: 6131.1656 - val_mean_squared_error: 6131.1582\n",
      "Epoch 63/100\n",
      "35561/35561 [==============================] - 23s 634us/sample - loss: 5761.8173 - mean_squared_error: 5761.7407 - val_loss: 2010.0860 - val_mean_squared_error: 2010.0894\n",
      "Epoch 64/100\n",
      "35561/35561 [==============================] - 22s 631us/sample - loss: 5845.1839 - mean_squared_error: 5845.1216 - val_loss: 3121.2387 - val_mean_squared_error: 3121.2324\n",
      "Epoch 65/100\n",
      "35561/35561 [==============================] - 22s 626us/sample - loss: 5593.0532 - mean_squared_error: 5592.9746 - val_loss: 4406.9524 - val_mean_squared_error: 4406.9497\n",
      "Epoch 66/100\n",
      "35561/35561 [==============================] - 22s 628us/sample - loss: 5984.1974 - mean_squared_error: 5984.1519 - val_loss: 3311.6551 - val_mean_squared_error: 3311.6506\n",
      "Epoch 67/100\n",
      "35561/35561 [==============================] - 23s 637us/sample - loss: 5452.4884 - mean_squared_error: 5452.4087 - val_loss: 2452.8720 - val_mean_squared_error: 2452.8713\n",
      "Epoch 68/100\n",
      "35561/35561 [==============================] - 23s 643us/sample - loss: 5853.5869 - mean_squared_error: 5853.5073 - val_loss: 3799.5882 - val_mean_squared_error: 3799.5901\n",
      "Epoch 69/100\n",
      "35561/35561 [==============================] - 22s 630us/sample - loss: 6036.7443 - mean_squared_error: 6036.6606 - val_loss: 2768.2418 - val_mean_squared_error: 2768.2415\n",
      "Epoch 70/100\n",
      "35561/35561 [==============================] - 23s 634us/sample - loss: 5569.7414 - mean_squared_error: 5569.6304 - val_loss: 2737.9220 - val_mean_squared_error: 2737.9172\n",
      "Epoch 71/100\n",
      "35561/35561 [==============================] - 23s 640us/sample - loss: 9308.4967 - mean_squared_error: 9308.3506 - val_loss: 4078.1401 - val_mean_squared_error: 4078.1387\n",
      "Epoch 72/100\n",
      "35561/35561 [==============================] - 22s 609us/sample - loss: 5357.1838 - mean_squared_error: 5357.1211 - val_loss: 4062.4047 - val_mean_squared_error: 4062.3953\n",
      "Epoch 73/100\n",
      "35561/35561 [==============================] - 22s 621us/sample - loss: 5867.5493 - mean_squared_error: 5867.5186 - val_loss: 3706.9115 - val_mean_squared_error: 3706.9111\n",
      "Epoch 74/100\n",
      "35561/35561 [==============================] - 21s 604us/sample - loss: 5809.2619 - mean_squared_error: 5809.2402 - val_loss: 2465.9220 - val_mean_squared_error: 2465.9270\n",
      "Epoch 75/100\n",
      "35561/35561 [==============================] - 22s 612us/sample - loss: 5788.5990 - mean_squared_error: 5788.5811 - val_loss: 3099.5355 - val_mean_squared_error: 3099.5342\n",
      "Epoch 76/100\n",
      "35561/35561 [==============================] - 22s 613us/sample - loss: 4840.9729 - mean_squared_error: 4840.9360 - val_loss: 2396.3391 - val_mean_squared_error: 2396.3406\n",
      "Epoch 77/100\n",
      "35561/35561 [==============================] - 22s 614us/sample - loss: 4097.3935 - mean_squared_error: 4097.3750 - val_loss: 1780.1404 - val_mean_squared_error: 1780.1411\n",
      "Epoch 78/100\n",
      "35178/35561 [============================>.] - ETA: 0s - loss: 3093.1657 - mean_squared_error: 3093.1484Executing shutdown due to inactivity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-08 16:09:09,616 - INFO     - Executing shutdown due to inactivity...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35561/35561 [==============================] - 25s 701us/sample - loss: 3060.7269 - mean_squared_error: 3060.7087 - val_loss: 2177.8457 - val_mean_squared_error: 2177.8384\n",
      "Epoch 79/100\n",
      "15834/35561 [============>.................] - ETA: 11s - loss: 9918.8144 - mean_squared_error: 9918.8203 Executing shutdown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-08 16:09:22,595 - INFO     - Executing shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35561/35561 [==============================] - 23s 655us/sample - loss: 4552.6154 - mean_squared_error: 4552.5532 - val_loss: 2489.6518 - val_mean_squared_error: 2489.6497\n",
      "Epoch 80/100\n",
      "35561/35561 [==============================] - 22s 628us/sample - loss: 5963.8657 - mean_squared_error: 5963.8462 - val_loss: 2939.4675 - val_mean_squared_error: 2939.4639\n",
      "Epoch 81/100\n",
      "35561/35561 [==============================] - 23s 656us/sample - loss: 4634.4773 - mean_squared_error: 4634.4414 - val_loss: 2173.8590 - val_mean_squared_error: 2173.8584\n",
      "Epoch 82/100\n",
      "35561/35561 [==============================] - 22s 624us/sample - loss: 5161.6402 - mean_squared_error: 5161.6343 - val_loss: 1889.7527 - val_mean_squared_error: 1889.7505\n",
      "Epoch 83/100\n",
      "35561/35561 [==============================] - 23s 642us/sample - loss: 3367.9308 - mean_squared_error: 3367.9199 - val_loss: 20027.1644 - val_mean_squared_error: 20027.1426\n",
      "Epoch 84/100\n",
      "35561/35561 [==============================] - 22s 630us/sample - loss: 5991.9408 - mean_squared_error: 5991.8569 - val_loss: 2202.0398 - val_mean_squared_error: 2202.0425\n",
      "Epoch 85/100\n",
      "35561/35561 [==============================] - 22s 631us/sample - loss: 4166.8984 - mean_squared_error: 4166.8867 - val_loss: 4373.2784 - val_mean_squared_error: 4373.2749\n",
      "Epoch 86/100\n",
      "35561/35561 [==============================] - 22s 631us/sample - loss: 2495.2816 - mean_squared_error: 2495.2688 - val_loss: 4030.2529 - val_mean_squared_error: 4030.2512\n",
      "Epoch 87/100\n",
      "35561/35561 [==============================] - 22s 620us/sample - loss: 4515.2320 - mean_squared_error: 4515.2168 - val_loss: 1966.6393 - val_mean_squared_error: 1966.6371\n",
      "Epoch 88/100\n",
      "35561/35561 [==============================] - 23s 633us/sample - loss: 3641.3355 - mean_squared_error: 3641.3135 - val_loss: 4766.4220 - val_mean_squared_error: 4766.4214\n",
      "Epoch 89/100\n",
      "35561/35561 [==============================] - 22s 629us/sample - loss: 4876.2774 - mean_squared_error: 4876.1953 - val_loss: 2804.2139 - val_mean_squared_error: 2804.2158\n",
      "Epoch 90/100\n",
      "35561/35561 [==============================] - 22s 626us/sample - loss: 5153.2319 - mean_squared_error: 5153.1719 - val_loss: 5717.6565 - val_mean_squared_error: 5717.6621\n",
      "Epoch 91/100\n",
      "35561/35561 [==============================] - 23s 633us/sample - loss: 2383.4483 - mean_squared_error: 2383.4363 - val_loss: 3686.2503 - val_mean_squared_error: 3686.2495\n",
      "Epoch 92/100\n",
      "35561/35561 [==============================] - 22s 622us/sample - loss: 3783.4386 - mean_squared_error: 3783.4082 - val_loss: 5017.4629 - val_mean_squared_error: 5017.4746\n",
      "Epoch 93/100\n",
      "35561/35561 [==============================] - 22s 629us/sample - loss: 4044.3280 - mean_squared_error: 4044.3213 - val_loss: 1961.5687 - val_mean_squared_error: 1961.5674\n",
      "Epoch 94/100\n",
      "35561/35561 [==============================] - 23s 635us/sample - loss: 4281.7301 - mean_squared_error: 4281.7246 - val_loss: 4644.8577 - val_mean_squared_error: 4644.8594\n",
      "Epoch 95/100\n",
      "35561/35561 [==============================] - 22s 626us/sample - loss: 2521.4178 - mean_squared_error: 2521.4060 - val_loss: 6188.9349 - val_mean_squared_error: 6188.9346\n",
      "Epoch 96/100\n",
      "35561/35561 [==============================] - 22s 631us/sample - loss: 2203.5268 - mean_squared_error: 2203.5229 - val_loss: 2934.7343 - val_mean_squared_error: 2934.7327\n",
      "Epoch 97/100\n",
      "35561/35561 [==============================] - 23s 640us/sample - loss: 3404.5591 - mean_squared_error: 3404.5466 - val_loss: 5167.2110 - val_mean_squared_error: 5167.2026\n",
      "Epoch 98/100\n",
      "35561/35561 [==============================] - 22s 624us/sample - loss: 4678.1385 - mean_squared_error: 4678.0601 - val_loss: 5818.3435 - val_mean_squared_error: 5818.3364\n",
      "Epoch 99/100\n",
      "35561/35561 [==============================] - 23s 637us/sample - loss: 4749.9633 - mean_squared_error: 4749.8921 - val_loss: 9724.7964 - val_mean_squared_error: 9724.7842\n",
      "Epoch 100/100\n",
      "35561/35561 [==============================] - 22s 624us/sample - loss: 4105.0371 - mean_squared_error: 4104.9971 - val_loss: 2731.0976 - val_mean_squared_error: 2731.0950\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=2, epochs=100, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.37748995603209\n",
      "3761.156311266845\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "pred_train = model.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train)))\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11114/11114 [==============================] - 0s 27us/sample - loss: 14146296.4569 - mean_squared_error: 14146253.0000\n",
      "Test Score: 14146296.456905723\n",
      "Test Accuracity 14146253.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print('Test Score:', score[0])\n",
    "print('Test Accuracity', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
